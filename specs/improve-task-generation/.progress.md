# Progress: improve-task-generation

## Original Goal
I want to really improve how we generate tasks, like make sure it makes ALOT of tasks, as small / tiny as it can I really want it that they would be super clear and structured, and we even should encourage the implement to add more tasks or change existing ones if it deems necessary

## Interview Format
- Version: 1.0

## Intent Classification
- Type: REFACTOR
- Confidence: medium (1 keyword matched)
- Min questions: 3
- Max questions: 5
- Keywords matched: improve

## Interview Responses

### Goal Interview (from start.md)
- Problem: All of the above — tasks are too large/coarse-grained, not enough tasks generated, and tasks lack clarity and structure
- Constraints: Both task-planner and executor can modify tasks, with guardrails — executor can suggest changes but must follow a protocol (e.g., update tasks.md, log reasoning)
- Success criteria: Small atomic tasks with clear acceptance criteria per task, executor rarely needs to improvise, plus dynamic adaptation — executor can adapt the plan when needed
- Additional context: User referenced GSD (get-shit-done) framework as inspiration for task structure

## Research Phase
- Parallel team research completed
- Topics researched: 5 (atomic task decomposition, dynamic task modification, task-planner analysis, spec-executor analysis, existing tasks.md quality)
- Teammate count: 5 (2 research-analyst, 3 Explore)
- Additional direct research: GSD framework (planner, executor, plan-phase)
- Key finding: Current tasks average 22.4 per spec; target should be 40-60+ with atomic granularity
- Key finding: GSD uses max 2-3 tasks per plan with strict specificity requirements
- Key finding: Dynamic task modification needs structured executor→coordinator communication protocol

### Requirements Interview (from requirements.md)
- Primary users: AI agents (executor/planner) — the spec-executor and task-planner agents are the primary consumers of the improved task format
- Priority tradeoffs: Balanced approach — equal weight on both better initial generation AND dynamic modification capabilities
- Success criteria: Both + measurable quality improvement — more tasks, dynamic adaptation, AND fewer executor failures/improvisations

## Learnings
- Task-planner.md is ~485 lines; adding sizing rules + examples must stay concise to avoid prompt bloat (target < 8000 tokens total)
- implement.md coordinator already has fix task generation (section 6c) — modification request handling should follow same insertion pattern (Edit tool after task block)
- templates/tasks.md still has "Manual test of core flow" in POC Checkpoint Verify field (line 70) — contradicts no-manual-tasks rule, must fix
- spec-executor has no output channel to coordinator besides TASK_COMPLETE/failure — new TASK_MODIFICATION_REQUEST signal is a net-new protocol addition
- fixTaskMap in state already tracks per-task attempts — modification tracking can follow same pattern (modificationMap)
- Related spec parallel-task-execution uses [P] markers; task modifications must not insert tasks mid-parallel-batch to avoid breaking batch boundaries
- 15% of existing tasks use vague verification — template examples are the highest-leverage fix for this
- Design: Sizing rules section adds ~300 tokens to task-planner.md (well under 8000 budget). Quality checklist expansion adds ~100 tokens. Total planner ~4900 tokens.
- Design: TASK_MODIFICATION_REQUEST uses JSON payload with embedded markdown task blocks — JSON for coordinator parsing, markdown for tasks.md consistency
- Design: SPLIT_TASK sends both TASK_MODIFICATION_REQUEST + TASK_COMPLETE (executor done with its part). ADD_PREREQUISITE sends only TASK_MODIFICATION_REQUEST (task blocked).
- Design: modificationMap is separate from fixTaskMap — different semantics (proactive adaptation vs reactive recovery). Both can exist for same task independently.
- Design: Parallel batch interaction — modification request breaks parallel batch, remaining tasks re-evaluated as sequential. Prevents mid-batch insertion corruption.
- Design: 7 files modified total. Largest change is implement.md (~80 lines for Section 6e). All other files < 50 lines added.
- Design: Backwards compatibility ensured via jq `//=` defaults for new state fields (modificationMap, maxModificationsPerTask, maxModificationDepth)

### Design Interview (from design.md)
- Architecture style: Extend existing architecture — modify task-planner.md, spec-executor.md, implement.md, and templates in-place
- Technology constraints: No constraints — stick with markdown prompts and existing tooling
- Integration approach: Use existing APIs and interfaces — extend TASK_COMPLETE protocol with new signals, use existing state management patterns

### Tasks Interview (from tasks.md)
- Testing depth: Standard - unit + integration — unit tests and integration tests where applicable, balanced for a markdown-prompt plugin
- Deployment approach: Standard CI/CD pipeline — push changes, let existing CI checks validate
- Execution priority: Balanced - reasonable quality with speed — decent quality throughout without over-engineering

### Design Update: Karpathy Coding Principles Integration
- Karpathy principles (think-first, simplicity, surgical, goal-driven) distributed across components at point-of-use rather than centralized
- Planner gets simplicity + surgical principles in Task Sizing Rules — prevents over-engineered task descriptions
- Executor gets think-first principle in Task Modification Requests — surfaces uncertainties via TASK_MODIFICATION_REQUEST instead of silently improvising
- Template gets all 4 principles as "Task Writing Principles" subsection — serves as quick reference for task authors
- Goal-driven principle is highest-impact change: shifts emphasis from Do steps (imperative) to Done when/Verify (declarative success criteria)
- Multi-step verify pattern `1. [Step] -> verify: [check]` from Karpathy aligns naturally with existing task Verify field convention
- 4th bad/good example pair added to template demonstrating imperative-to-goal-driven transformation
- Quality checklist expanded with 4 new principle-based checks (meaningful Done when, no speculative features, no unrelated files, explicit assumptions)
- Token impact modest: ~100 extra tokens in planner, ~150 extra in template. Still well under 8000 budget

## Completed Tasks
- [x] 1.1 Add Task Writing Guide header and principles to templates/tasks.md
- [x] 1.2 Add Bad vs Good Example 1 (File Creation) to templates/tasks.md
- [x] 1.3 Add Bad vs Good Example 2 (Integration) to templates/tasks.md
- [x] 1.4 [VERIFY] Quality checkpoint: grep validation of template structure
- [x] 1.5 Add Bad vs Good Example 3 (Refactoring) to templates/tasks.md

## Current Task
Awaiting next task

## Next
Task 1.6: Add Bad vs Good Example 4 (Goal-Driven) to templates/tasks.md

### Task Planning
- 48 total tasks across 5 phases: Phase 1 (38 tasks, 79%), Phase 2 (6 tasks, 13%), Phase 3 (10 tasks, 21%), Phase 4 (3 tasks, 6%), Phase 5 (3 tasks, 6%) -- note: percentages reflect checkpoint overlap
- Phase 1 is largest because each file modification is broken into atomic tasks (1 section insertion per task) with quality checkpoints every 2-3 tasks
- Key dependency: schema tasks (1.20-1.22) should complete before implement.md state init (1.23) since the schema defines the structure that init creates
- Line numbers in design doc are pre-insertion; executor must use content-based matching (Edit tool old_string/new_string) not line numbers since earlier insertions shift lines
- All 7 files are markdown/JSON prompt files with no build step -- verification is purely grep/jq based
- No existing test framework (no package.json, no pnpm) -- CI uses bats-tests.yml, plugin-version-check.yml, spec-file-check.yml
- Version bump from 3.4.1 to 3.5.0 (minor: new feature) in both plugin.json and marketplace.json
- templates/tasks.md "Manual test" at line 70 is the only manual verification pattern found in templates; will be fixed in task 1.7

### Verification: 1.4 [VERIFY] Quality checkpoint: grep validation of template structure
- Status: PASS
- Check 1: `grep -c "### Bad vs. Good Examples"` = 1 (expected 1) -- PASS
- Check 2: `grep -c "Example 1:"` = 1 (expected 1) -- PASS
- Check 3: `grep -c "Example 2:"` = 1 (expected 1) -- PASS
- Structural order verified: Task Writing Guide (L29) > Principles (L33) > Bad vs Good Examples (L40) > Example 1 (L42) > Example 2 (L60) > Phase 1 (L78)
- No fixes needed, no commit required
